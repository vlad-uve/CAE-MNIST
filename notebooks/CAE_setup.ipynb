{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlad-uve/CAE-MNIST/blob/main/notebooks/CAE_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ub956SEtIlI"
      },
      "outputs": [],
      "source": [
        "# Create project folder structure\n",
        "!mkdir -p ./CAE_setup_local/src\n",
        "!mkdir -p ./CAE_setup_local/notebooks\n",
        "!mkdir -p ./CAE_setup_local/outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPxRXhhL85Dx",
        "outputId": "af65dde9-4b43-4e76-9334-e56b40d52bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your GitHub token··········\n",
            "Cloning into 'CAE-MNIST'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 367 (delta 43), reused 38 (delta 13), pack-reused 279 (from 1)\u001b[K\n",
            "Receiving objects: 100% (367/367), 14.74 MiB | 12.99 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "token = getpass(\"Paste your GitHub token\")\n",
        "\n",
        "user_name = 'vlad-uve'\n",
        "repo_name = 'CAE-MNIST'\n",
        "repo_url = f\"https://{token}@github.com/{user_name}/{repo_name}.git\"\n",
        "\n",
        "!git config --global user.email \"vladislav.yushkevich.uve@gmail.com\"\n",
        "!git config --global user.name \"vlad_uve\"\n",
        "\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def push_to_git(file_path, commit_msg):\n",
        "\n",
        "    git_repo_path = '/content/CAE-MNIST'\n",
        "    local_repo_path = '/content/CAE_setup_local'\n",
        "    git_file_path = f'{git_repo_path}/{file_path}'\n",
        "    local_file_path = f'{local_repo_path}/{file_path}'\n",
        "\n",
        "    # Remove the existing file in the Git repo if it exists\n",
        "    if os.path.exists(git_file_path):\n",
        "        os.remove(git_file_path)\n",
        "\n",
        "    # Copy the updated file from setup to git repo\n",
        "    os.makedirs(os.path.dirname(git_file_path), exist_ok=True)\n",
        "    shutil.copy2(local_file_path, git_file_path)\n",
        "\n",
        "    # Git add, commit, and push using -C to avoid %cd side effects\n",
        "    !git -C $git_repo_path add $git_file_path\n",
        "    !git -C $git_repo_path commit -m \"$commit_msg\" || echo \"⚠️ Nothing to commit\"\n",
        "    !git -C $git_repo_path push origin main"
      ],
      "metadata": {
        "id": "AlXR3iKGLUcz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VXIpDzNmb8L"
      },
      "source": [
        "# Model Classes Setup: AutoEncoder, DeepAutoEncoder, ShallowEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q9x4o2T8BrV",
        "outputId": "de7453a6-9dc8-4acd-84fd-8063bf80fd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/src/model.py\n"
          ]
        }
      ],
      "source": [
        "# write encoder, decoder and autoencoder classes to local src as model.py\n",
        "%%writefile ./CAE_setup_local/src/model.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # define convolutional layers for encoding\n",
        "        self.encn1 = nn.Conv2d(1, n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.encn2 = nn.Conv2d(n_channels[0], n_channels[1], 4, stride=stride, padding=padding)\n",
        "        self.encn3 = nn.Conv2d(n_channels[1], n_channels[2], 3, stride=stride, padding=padding)\n",
        "\n",
        "        # optional batch normalization layers after each conv\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[0])\n",
        "            self.bn2 = nn.BatchNorm2d(n_channels[1])\n",
        "            self.bn3 = nn.BatchNorm2d(n_channels[2])\n",
        "        else:\n",
        "            self.bn1 = self.bn2 = self.bn3 = nn.Identity()\n",
        "\n",
        "        # flatten and fully connected bottleneck layer\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(n_channels[2] * 4 * 4, latent_dim)\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # pass through encoding layers with batchnorm and activation\n",
        "        x = self.encn1(input_x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        # return data encoded in latent space with flattening and fully connected layer\n",
        "        x = self.flatten(x)\n",
        "        encoded_x = self.fc1(x)\n",
        "\n",
        "        return encoded_x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # fully connected + unflatten to prepare for decoding\n",
        "        self.fc1 = nn.Linear(latent_dim, n_channels[2] * 4 * 4)\n",
        "        self.unflatten = nn.Unflatten(1, (n_channels[2], 4, 4))\n",
        "\n",
        "        # optional batch normalization layers after each transposed conv\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[1])\n",
        "            self.bn2 = nn.BatchNorm2d(n_channels[0])\n",
        "        else:\n",
        "            self.bn1 = self.bn2 = nn.Identity()\n",
        "\n",
        "        # define transposed conv layers for decoding\n",
        "        self.decn1 = nn.ConvTranspose2d(n_channels[2], n_channels[1], 3, stride=stride, padding=padding)\n",
        "        self.decn2 = nn.ConvTranspose2d(n_channels[1], n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.decn3 = nn.ConvTranspose2d(n_channels[0], 1, 4, stride=stride, padding=padding)\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, encoded):\n",
        "        #decoding data from latent space with unflattening of fully connected layer\n",
        "        x = self.fc1(encoded)\n",
        "        x = self.unflatten(x)\n",
        "\n",
        "        # pass through transposed conv layers with batchnorm and activation\n",
        "        x = self.decn1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn3(x)\n",
        "        decoded_x = F.sigmoid(x)\n",
        "\n",
        "        # return decoded data as an image with pixels of [0, 1] range\n",
        "        return decoded_x\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, n_channels, latent_dim, use_batch_norm=False, activation_func='relu'):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # fixed parameters for all conv layers\n",
        "        stride = 2\n",
        "        padding = 1\n",
        "\n",
        "        # define encoder and decoder blocks\n",
        "        self.encoder = Encoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "        self.decoder = Decoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # encode and decode the input data\n",
        "        encoded_x = self.encoder(input_x)\n",
        "        decoded_x = self.decoder(encoded_x)\n",
        "\n",
        "        return decoded_x, encoded_x\n",
        "\n",
        "\n",
        "class DeepEncoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(DeepEncoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # define convolutional layers for encoding\n",
        "        self.encn1 = nn.Conv2d(1, n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.encn2 = nn.Conv2d(n_channels[0], n_channels[1], 4, stride=stride, padding=padding)\n",
        "        self.encn3 = nn.Conv2d(n_channels[1], n_channels[2], 3, stride=stride, padding=padding)\n",
        "        self.encn4 = nn.Conv2d(n_channels[2], n_channels[3], 4, stride=stride, padding=padding)\n",
        "\n",
        "        # optional batch normalization layers after each conv\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[0])\n",
        "            self.bn2 = nn.BatchNorm2d(n_channels[1])\n",
        "            self.bn3 = nn.BatchNorm2d(n_channels[2])\n",
        "            self.bn4 = nn.BatchNorm2d(n_channels[3])\n",
        "        else:\n",
        "            self.bn1 = self.bn2 = self.bn3 = self.bn4 = nn.Identity()\n",
        "\n",
        "        # flatten and fully connected bottleneck layer\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(n_channels[3] * 2 * 2, latent_dim)\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # pass through encoding layers with batchnorm and activation\n",
        "        x = self.encn1(input_x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        # flatten and pass through fully connected layer\n",
        "        x = self.flatten(x)\n",
        "        encoded_x = self.fc1(x)\n",
        "\n",
        "        return encoded_x\n",
        "\n",
        "\n",
        "class DeepDecoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(DeepDecoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # fully connected + unflatten to prepare for decoding\n",
        "        self.fc1 = nn.Linear(latent_dim, n_channels[3] * 2 * 2)\n",
        "        self.unflatten = nn.Unflatten(1, (n_channels[3], 2, 2))\n",
        "\n",
        "        # define transposed conv layers for decoding\n",
        "        self.decn1 = nn.ConvTranspose2d(n_channels[3], n_channels[2], 4, stride=stride, padding=padding)\n",
        "        self.decn2 = nn.ConvTranspose2d(n_channels[2], n_channels[1], 3, stride=stride, padding=padding)\n",
        "        self.decn3 = nn.ConvTranspose2d(n_channels[1], n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.decn4 = nn.ConvTranspose2d(n_channels[0], 1, 4, stride=stride, padding=padding)\n",
        "\n",
        "        # optional batch normalization layers after each transposed conv (except the last one)\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[2])\n",
        "            self.bn2 = nn.BatchNorm2d(n_channels[1])\n",
        "            self.bn3 = nn.BatchNorm2d(n_channels[0])\n",
        "        else:\n",
        "            self.bn1 = self.bn2 = self.bn3 = nn.Identity()\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, encoded):\n",
        "        # decoding from latent space\n",
        "        x = self.fc1(encoded)\n",
        "        x = self.unflatten(x)\n",
        "\n",
        "        x = self.decn1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn4(x)\n",
        "        decoded_x = F.sigmoid(x)\n",
        "\n",
        "        return decoded_x\n",
        "\n",
        "\n",
        "class DeepAutoEncoder(nn.Module):\n",
        "    def __init__(self, n_channels, latent_dim, use_batch_norm=False, activation_func='relu'):\n",
        "        super(DeepAutoEncoder, self).__init__()\n",
        "\n",
        "        # fixed parameters for all conv layers\n",
        "        stride = 2\n",
        "        padding = 1\n",
        "\n",
        "        # define encoder and decoder blocks\n",
        "        self.encoder = DeepEncoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "        self.decoder = DeepDecoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # encode and decode the input data\n",
        "        encoded_x = self.encoder(input_x)\n",
        "        decoded_x = self.decoder(encoded_x)\n",
        "\n",
        "        return decoded_x, encoded_x\n",
        "\n",
        "\n",
        "class ShallowEncoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(ShallowEncoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # define convolutional layers for encoding\n",
        "        self.encn1 = nn.Conv2d(1, n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.encn2 = nn.Conv2d(n_channels[0], n_channels[1], 4, stride=stride, padding=padding)\n",
        "\n",
        "        # optional batch normalization layers after each conv\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[0])\n",
        "            self.bn2 = nn.BatchNorm2d(n_channels[1])\n",
        "        else:\n",
        "            self.bn1 = self.bn2 = nn.Identity()\n",
        "\n",
        "        # flatten and fully connected bottleneck layer\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(n_channels[1] * 7 * 7, latent_dim)\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # pass through encoding layers with batchnorm and activation\n",
        "        x = self.encn1(input_x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.encn2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        # flatten and pass through fully connected layer\n",
        "        x = self.flatten(x)\n",
        "        encoded_x = self.fc1(x)\n",
        "\n",
        "        return encoded_x\n",
        "\n",
        "\n",
        "class ShallowDecoder(nn.Module):\n",
        "    def __init__(self, n_channels, stride, padding, latent_dim, use_batch_norm, activation_func):\n",
        "        super(ShallowDecoder, self).__init__()\n",
        "\n",
        "        # store activation function choice\n",
        "        self.activation_func = activation_func\n",
        "\n",
        "        # fully connected + unflatten to prepare for decoding\n",
        "        self.fc1 = nn.Linear(latent_dim, n_channels[1] * 7 * 7)\n",
        "        self.unflatten = nn.Unflatten(1, (n_channels[1], 7, 7))\n",
        "\n",
        "        # define transposed conv layers for decoding\n",
        "        self.decn1 = nn.ConvTranspose2d(n_channels[1], n_channels[0], 4, stride=stride, padding=padding)\n",
        "        self.decn2 = nn.ConvTranspose2d(n_channels[0], 1, 4, stride=stride, padding=padding)\n",
        "\n",
        "        # optional batch normalization layers (no batch norm after final layer)\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm2d(n_channels[0])\n",
        "        else:\n",
        "            self.bn1 = nn.Identity()\n",
        "\n",
        "    def apply_activation(self, x):\n",
        "        # safely apply activation function\n",
        "        if self.activation_func == 'relu':\n",
        "            return F.relu(x)\n",
        "        elif self.activation_func == 'leaky_relu':\n",
        "            return F.leaky_relu(x)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation function: {self.activation_func}\")\n",
        "\n",
        "    def forward(self, encoded):\n",
        "        # decode from latent space\n",
        "        x = self.fc1(encoded)\n",
        "        x = self.unflatten(x)\n",
        "\n",
        "        x = self.decn1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.apply_activation(x)\n",
        "\n",
        "        x = self.decn2(x)\n",
        "        decoded_x = F.sigmoid(x)\n",
        "\n",
        "        return decoded_x\n",
        "\n",
        "\n",
        "class ShallowAutoEncoder(nn.Module):\n",
        "    def __init__(self, n_channels, latent_dim, use_batch_norm=False, activation_func='relu'):\n",
        "        super(ShallowAutoEncoder, self).__init__()\n",
        "\n",
        "        # fixed parameters for all conv layers\n",
        "        stride = 2\n",
        "        padding = 1\n",
        "\n",
        "        # define encoder and decoder blocks\n",
        "        self.encoder = ShallowEncoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "        self.decoder = ShallowDecoder(n_channels, stride, padding, latent_dim, use_batch_norm, activation_func)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # encode and decode the input data\n",
        "        encoded_x = self.encoder(input_x)\n",
        "        decoded_x = self.decoder(encoded_x)\n",
        "\n",
        "        return decoded_x, encoded_x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model.py to Git\n",
        "push_to_git('src/model.py', 'Update model.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAVUDKPOIXNo",
        "outputId": "ed68dfa1-7aaa-434e-c8f1-4627a2bf04d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main a46f7df] Update model.py\n",
            " 1 file changed, 250 insertions(+)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 1.67 KiB | 1.67 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/vlad-uve/CAE-MNIST.git\n",
            "   6285d54..a46f7df  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p8_0sl_Gt8h"
      },
      "source": [
        "# Model Training Functions Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkuF_m9ZGx0l",
        "outputId": "049d65cc-5af0-4566-9019-37f832d52d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/src/train.py\n"
          ]
        }
      ],
      "source": [
        "# write model training, model validation, and full model traning run functions to local src as train.py\n",
        "%%writefile ./CAE_setup_local/src/train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_model(model, train_dataloader, optimizer, epoch, device):\n",
        "    \"\"\"\n",
        "    Runs one training epoch for the given model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): the autoencoder to train\n",
        "        train_dataloader (DataLoader): training data loader\n",
        "        optimizer (torch.optim.Optimizer): optimizer used for training\n",
        "        epoch (int): current epoch number (used for tracking/logging)\n",
        "\n",
        "    Returns:\n",
        "        float: loss value from the last batch of the epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for b_i, (input_x, _) in enumerate(train_dataloader):\n",
        "        # move batch to device\n",
        "        input_x = input_x.to(device)\n",
        "\n",
        "        # clear previous gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass: get model output\n",
        "        decoded_x, encoded_x = model(input_x)\n",
        "\n",
        "        # compute reconstruction loss between input and output\n",
        "        loss = F.binary_cross_entropy(decoded_x, input_x)\n",
        "\n",
        "        # backward pass: compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    # return last batch loss\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def validate_model(model, validation_dataloader, device):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the validation set using binary cross-entropy loss.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): trained autoencoder\n",
        "        validation_dataloader (DataLoader): validation data loader\n",
        "        device (str): 'cuda' or 'cpu'\n",
        "\n",
        "    Returns:\n",
        "        float: average loss over the entire validation set\n",
        "    \"\"\"\n",
        "\n",
        "    # set model to evaluation mode (disables dropout, batchnorm updates etc.)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    # disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for input_x, _ in validation_dataloader:\n",
        "            # move batch to device\n",
        "            input_x = input_x.to(device)\n",
        "\n",
        "            # forward pass\n",
        "            decoded_x, encoded_x = model(input_x)\n",
        "\n",
        "            # accumulate reconstruction loss for each bath\n",
        "            total_loss += F.binary_cross_entropy(decoded_x, input_x)\n",
        "\n",
        "    # compute and return average loss over validation over one epoch\n",
        "    avg_loss = total_loss / len(validation_dataloader)\n",
        "\n",
        "    return avg_loss.item()\n",
        "\n",
        "\n",
        "def run_model_training(model, train_dataloader, validation_dataloader, optimizer, scheduler, num_epoch, device):\n",
        "    \"\"\"\n",
        "    Trains the model across multiple epochs and evaluates on validation set.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): the autoencoder\n",
        "        train_dataloader (DataLoader): training data\n",
        "        validation_dataloader (DataLoader): validation data\n",
        "        optimizer (Optimizer): optimizer for training\n",
        "        scheduler (LRScheduler): learning rate scheduler\n",
        "        num_epoch (int): number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        model: trained model\n",
        "        dict: loss history containing 'train', 'validation', and 'epoch' lists\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize loss tracking dictionary\n",
        "    loss_history = {'train': [], 'validation': [], 'epoch': []}\n",
        "\n",
        "    print('\\nTRAINING IS STARTED:')\n",
        "\n",
        "    # run training loop\n",
        "    for epoch in range(1, num_epoch + 1):\n",
        "        # train model on training set\n",
        "        train_loss = train_model(model, train_dataloader, optimizer, epoch, device)\n",
        "\n",
        "        # evaluate model on validation set\n",
        "        validation_loss = validate_model(model, validation_dataloader, device)\n",
        "\n",
        "        # check if scheduler reduces learning rate based on validation loss plateau\n",
        "        previous_lr = optimizer.param_groups[0]['lr']\n",
        "        scheduler.step(validation_loss)\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        if current_lr != previous_lr:\n",
        "            print(f\"LR reduced from {previous_lr:.4f} → {current_lr:.4f}\")\n",
        "\n",
        "        # record losses and epoch number\n",
        "        loss_history['train'].append(train_loss)\n",
        "        loss_history['validation'].append(validation_loss)\n",
        "        loss_history['epoch'].append(epoch)\n",
        "\n",
        "        # print progress\n",
        "        print(f\"Epoch {epoch:2d} | Train Loss: {train_loss:.4f} | Validation Loss: {validation_loss:.4f}\")\n",
        "\n",
        "    print('\\nTRAINING IS FINISHED.')\n",
        "\n",
        "    return model, loss_history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push train.py to Git\n",
        "push_to_git('src/train.py', 'Update train.py')"
      ],
      "metadata": {
        "id": "2T2MRQXrJ1fr",
        "outputId": "c36aeff3-3577-463d-d4f1-de576c2cbe0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "⚠️ Nothing to commit\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3XLxXYlmZPH"
      },
      "source": [
        "# Data Loaders Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7xo4noyD1pt",
        "outputId": "49bcdea3-9785-40c1-d715-db760b0c8b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/src/data.py\n"
          ]
        }
      ],
      "source": [
        "# write train and validation dataloader functions to src as data.py\n",
        "\n",
        "%%writefile ./CAE_setup_local/src/data.py\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_train_dataloader(batch_size=32, data_dir='../data'):\n",
        "    \"\"\"\n",
        "    Loads the MNIST training set and returns a DataLoader.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): size of each training batch\n",
        "        data_dir (str): path to MNIST data storage\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: PyTorch DataLoader for training data\n",
        "    \"\"\"\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=data_dir,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.ToTensor()\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    return train_dataloader\n",
        "\n",
        "\n",
        "def get_validation_dataloader(batch_size=500, data_dir='../data'):\n",
        "    \"\"\"\n",
        "    Loads the MNIST validation (test) set and returns a DataLoader.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): size of each validation batch\n",
        "        data_dir (str): path to MNIST data storage\n",
        "\n",
        "    Returns:\n",
        "        DataLoader: PyTorch DataLoader for validation data\n",
        "    \"\"\"\n",
        "    validation_dataset = datasets.MNIST(\n",
        "        root=data_dir,\n",
        "        train=False,\n",
        "        transform=transforms.ToTensor()\n",
        "    )\n",
        "\n",
        "    validation_dataloader = DataLoader(\n",
        "        validation_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return validation_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push data.py to Git\n",
        "push_to_git('src/data.py', 'Update data.py')"
      ],
      "metadata": {
        "id": "5Nc-qdgCOJjL",
        "outputId": "17bd76c0-ea79-489f-b3e6-ef8d33c798af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "⚠️ Nothing to commit\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq1fORex3Cb"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0sFBX7x-GO",
        "outputId": "9a1c5299-7c5b-4af9-b123-5546da8ff313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/src/evaluation.py\n"
          ]
        }
      ],
      "source": [
        "# write sampling and experiment reconstruction functions to src as evaluation.py\n",
        "\n",
        "%%writefile ./CAE_setup_local/src/evaluation.py\n",
        "\n",
        "import torch\n",
        "\n",
        "def get_image_samples(validation_dataloader):\n",
        "\n",
        "  # get a batch of images and labels from the validation set\n",
        "  images, labels = next(iter(validation_dataloader))\n",
        "\n",
        "  # select exactly one example for each digit (0-9)\n",
        "  sample_labels = [i for i in range(10)]\n",
        "  sample_indices = [torch.where(labels == i)[0][0].item() for i in range(10)]\n",
        "\n",
        "  sample_images = images[sample_indices]\n",
        "\n",
        "  return sample_images, sample_labels\n",
        "\n",
        "\n",
        "\n",
        "def get_experiment_reconstructions(model_list, original_images, device):\n",
        "    '''\n",
        "    Run models on input images and return reconstructed outputs.\n",
        "\n",
        "    Args:\n",
        "        model_list (list): list of trained models to evaluate\n",
        "        original_images (torch.Tensor): batch of original input images\n",
        "\n",
        "    Returns:\n",
        "        list of torch.Tensor: reconstructed images for each model\n",
        "    '''\n",
        "    reconstructions = []\n",
        "    for model in model_list:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            reconstructed_images, _ = model(original_images.to(device))\n",
        "            reconstructions.append(reconstructed_images.cpu())\n",
        "    return reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push evaluation.py to Git\n",
        "push_to_git('src/evaluation.py', 'Update evaluation.py')"
      ],
      "metadata": {
        "id": "mjUAHOahOOBe",
        "outputId": "e8e47d32-9662-491b-9956-030f2a3cc78f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "⚠️ Nothing to commit\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1znAgpg8eaz"
      },
      "source": [
        "# Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZinR8SKQfAq",
        "outputId": "97cf87ae-8b65-4247-d501-a1db487c0696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./CAE_setup_local/src/plotting.py\n"
          ]
        }
      ],
      "source": [
        "# write visulization helper function to src as plotting.py\n",
        "%%writefile ./CAE_setup_local/src/plotting.py\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def plot_baseline_history(baseline_loss, to_plot_train=False):\n",
        "    '''\n",
        "    Plot loss history for the baseline model.\n",
        "\n",
        "    Args:\n",
        "        baseline_loss (dict): dictionary with 'epoch', 'train', and 'validation' lists\n",
        "        to_plot_train (bool): if True, also plot training loss\n",
        "    '''\n",
        "\n",
        "    color=plt.get_cmap('tab10').colors\n",
        "\n",
        "    # optionally plot training losses\n",
        "    if to_plot_train:\n",
        "        plt.plot(baseline_loss['epoch'], baseline_loss['train'], label='Base model (training loss)', color=color[0], linestyle='--')\n",
        "\n",
        "    # plot validation losses\n",
        "    plt.plot(baseline_loss['epoch'], baseline_loss['validation'], label='Base model (validation loss)', color=color[0], linewidth=2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Baseline Model Loss')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def plot_experiment_history(loss_list, label_list, title, to_plot_train=False):\n",
        "    '''\n",
        "    Plot loss curves for multiple models.\n",
        "\n",
        "    Args:\n",
        "        loss_list (list of dict): list of loss history dictionaries (per model)\n",
        "        label_list (list of str): list of model names (same length as loss_list)\n",
        "        title (str): title for the plot\n",
        "        to_plot_train (bool): if True, also plot training loss curves\n",
        "\n",
        "    Each dictionary in loss_list must contain:\n",
        "        - 'epoch': list of epoch numbers\n",
        "        - 'train': list of training losses (optional if to_plot_train=False)\n",
        "        - 'validation': list of validation losses\n",
        "    '''\n",
        "\n",
        "    color=plt.get_cmap('tab20').colors\n",
        "\n",
        "    # loop over each loss history in the list\n",
        "    for i, (loss_history, label) in enumerate(zip(loss_list, label_list)):\n",
        "\n",
        "      # optionally plot training losses\n",
        "      if to_plot_train:\n",
        "          plt.plot(loss_history['epoch'], loss_history['train'], label=label + ' (training loss)', color=color[i+1], linestyle='--')\n",
        "\n",
        "      # plot validation losses\n",
        "      plt.plot(loss_history['epoch'], loss_history['validation'], label=label + ' (validation loss)', color=color[i+1], linewidth=2)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "def plot_digits_row(images, labels=None, title=None, cmap='magma', figsize=(15, 3)):\n",
        "    '''\n",
        "    Display a row of digit images side by side.\n",
        "\n",
        "    Args:\n",
        "        images (numpy array or torch tensor): array of images (n_images, height, width)\n",
        "        labels (list or array, optional): optional list of labels to display as titles\n",
        "        title (str, optional): overall title for the plot\n",
        "        cmap (str): matplotlib colormap for image display\n",
        "        figsize (tuple): figure size for the plot\n",
        "    '''\n",
        "\n",
        "    n_images = images.shape[0]\n",
        "\n",
        "    fig, axes = plt.subplots(1, n_images, figsize=figsize)\n",
        "\n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        # display each image\n",
        "        ax.imshow(images[idx], cmap=cmap)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # optionally set image label as title\n",
        "        if labels is not None:\n",
        "            ax.set_title(str(labels[idx]), fontsize=20)\n",
        "\n",
        "    # optionally set a main title for the plot\n",
        "    if title is not None:\n",
        "        plt.suptitle(title, y=1, fontsize=30)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # separator\n",
        "    print('\\n ')\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_experiment_reconstructions(reconstructions, labels, title_list):\n",
        "    '''\n",
        "    Plot reconstruction results for multiple models.\n",
        "\n",
        "    Args:\n",
        "        reconstructions (list of torch.Tensor): reconstructed outputs from models\n",
        "        labels (list or array): labels for each image\n",
        "        title_list (list of str): titles to display for each model\n",
        "    '''\n",
        "\n",
        "    figures = []\n",
        "\n",
        "    for recon, title in zip(reconstructions, title_list):\n",
        "        fig = plot_digits_row(\n",
        "            recon.squeeze(),\n",
        "            labels,\n",
        "            title=title + ' reconstructed digits'\n",
        "        )\n",
        "\n",
        "        figures.append(fig)\n",
        "\n",
        "    return figures"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push plotting.py to Git\n",
        "push_to_git('src/plotting.py', 'Update plotting.py')"
      ],
      "metadata": {
        "id": "v594jp0WOb51",
        "outputId": "cbc78a94-e479-4687-8f98-6f7aa7c868d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 38f432a] Update plotting.py\n",
            " 1 file changed, 1 insertion(+)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 376 bytes | 376.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/vlad-uve/CAE-MNIST.git\n",
            "   64b1020..38f432a  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting Functions"
      ],
      "metadata": {
        "id": "egjgJtBJSBNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write fil exporting fucntions to src as export.py\n",
        "%%writefile ./CAE_setup_local/src/export.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "def save_experiment_files(\n",
        "    experiment_name,\n",
        "    models,\n",
        "    losses,\n",
        "    reconstructions,\n",
        "    description_text,\n",
        "    local_path_root='/content'\n",
        "):\n",
        "    \"\"\"\n",
        "    Save experiment files: model weights, loss history, reconstructions, and description.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): e.g., \"experiment_2\"\n",
        "        models (list): list of trained model objects\n",
        "        losses (list): list of loss history objects\n",
        "        reconstructions (list): list of reconstructed image tensors\n",
        "        description_text (str): plain-text description\n",
        "        local_path_root (str): where to create the export folder (default: '/content')\n",
        "    \"\"\"\n",
        "\n",
        "    export_folder = os.path.join(local_path_root, f'CAE_{experiment_name}_local')\n",
        "    os.makedirs(export_folder, exist_ok=True)\n",
        "\n",
        "    for idx, (model, loss, recon) in enumerate(zip(models, losses, reconstructions)):\n",
        "        torch.save(model.state_dict(), os.path.join(export_folder, f'{experiment_name}_model_{idx+1}.pth'))\n",
        "        torch.save(loss, os.path.join(export_folder, f'{experiment_name}_loss_{idx+1}.pth'))\n",
        "        torch.save(recon, os.path.join(export_folder, f'{experiment_name}_reconstruction_{idx+1}.pth'))\n",
        "\n",
        "    with open(os.path.join(export_folder, f'{experiment_name}_description.txt'), 'w') as f:\n",
        "        f.write(description_text.strip())\n",
        "\n",
        "    print(f\"✅ Saved {experiment_name} files to: {export_folder}\")\n",
        "\n",
        "\n",
        "def export_experiment_files(experiment_name, model_count,\n",
        "                            local_root='/content',\n",
        "                            repo_root='/content/CAE-MNIST'):\n",
        "    \"\"\"\n",
        "    Copies experiment output files from local folder to Git repo and pushes them.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): e.g. \"experiment_2\"\n",
        "        model_count (int): number of models/files to export\n",
        "        local_root (str): path where local files are stored (default: /content)\n",
        "        repo_root (str): path to the cloned Git repo (default: /content/CAE-MNIST)\n",
        "    \"\"\"\n",
        "\n",
        "    # Define folders\n",
        "    local_export_folder = os.path.join(local_root, f'CAE_{experiment_name}_local')\n",
        "    git_output_folder = os.path.join(repo_root, 'outputs', f'{experiment_name}_files')\n",
        "    os.makedirs(git_output_folder, exist_ok=True)\n",
        "\n",
        "    # Gather file names\n",
        "    files_to_copy = []\n",
        "\n",
        "    # Collect filenames to copy\n",
        "    for idx in range(0, model_count):\n",
        "      files_to_copy.append(f'{experiment_name}_model_{idx+1}.pth')\n",
        "      files_to_copy.append(f'{experiment_name}_loss_{idx+1}.pth')\n",
        "      files_to_copy.append(f'{experiment_name}_reconstruction_{idx+1}.pth')\n",
        "\n",
        "    # Add description\n",
        "    files_to_copy.append(f'{experiment_name}_description.txt')\n",
        "\n",
        "    # Copy files into Git folder\n",
        "    for file in files_to_copy:\n",
        "        shutil.copy2(\n",
        "            os.path.join(local_export_folder, file),\n",
        "            os.path.join(git_output_folder, file)\n",
        "        )\n",
        "\n",
        "    # Git add, commit, push\n",
        "    os.chdir(repo_root)\n",
        "    os.system(f'git add outputs/{experiment_name}_files/*')\n",
        "    os.system(f'git commit -m \"Add {experiment_name}: models, losses, reconstructions, and description\" || echo \"Nothing to commit\"')\n",
        "    os.system('git push origin main')\n",
        "\n",
        "    print(f\"✅ Exported {experiment_name} files to: outputs/{experiment_name}_files/\")"
      ],
      "metadata": {
        "id": "r5wmvP0LOcFd",
        "outputId": "eae51c6f-1c6d-489a-c298-f950383bde62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/src/export.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push export.py to Git\n",
        "push_to_git('src/export.py', 'Update export.py')"
      ],
      "metadata": {
        "id": "Y6yNnQS1Ogob",
        "outputId": "c187a7af-e2b0-49af-cbad-33f5725c8d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 45b1280] Update export.py\n",
            " 1 file changed, 3 insertions(+), 1 deletion(-)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 400 bytes | 400.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/vlad-uve/CAE-MNIST.git\n",
            "   c00002b..45b1280  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQbPCDH2SlJh"
      },
      "source": [
        "# Git Ignore Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldjYNPw4_8Ze",
        "outputId": "5ff4401b-f8a6-4db7-9c80-fe86e7efde8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./CAE_setup_local/.gitignore\n"
          ]
        }
      ],
      "source": [
        "# write gitignore\n",
        "%%writefile ./CAE_setup_local/.gitignore\n",
        "\n",
        "%%writefile /content/CAE-MNIST/.gitignore\n",
        "# Ignore everything in outputs/ by default\n",
        "outputs/**\n",
        "\n",
        "# Allow experiment folders with valid files\n",
        "!outputs/**/\n",
        "!outputs/**/*.pth\n",
        "!outputs/**/*.pt\n",
        "!outputs/**/*.txt\n",
        "!outputs/**/*.json\n",
        "!outputs/**/*.csv\n",
        "!outputs/**/*.png\n",
        "!outputs/**/*.jpg\n",
        "\n",
        "\n",
        "# Ignore all __pycache__ and checkpoint junk\n",
        "__pycache__/\n",
        ".ipynb_checkpoints/\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Push .gitignore to Git\n",
        "push_to_git('.gitignore', 'Added global .gitignore for structured experiment outputs')"
      ],
      "metadata": {
        "id": "ijHf8vl9OxsN",
        "outputId": "d27b6369-dec9-434f-e03f-fc24beff93e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "⚠️ Nothing to commit\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2VXIpDzNmb8L",
        "2p8_0sl_Gt8h",
        "P3XLxXYlmZPH",
        "hWq1fORex3Cb",
        "Q1znAgpg8eaz"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}