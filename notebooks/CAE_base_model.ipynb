{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlad-uve/CAE-MNIST/blob/main/notebooks/CAE_base_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNve2HZmCqnL"
      },
      "source": [
        "# Libraries & Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpjvnnJrDEZZ"
      },
      "outputs": [],
      "source": [
        "# PyTorch core\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Data loading and transformations\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Model summary utility\n",
        "from torchsummary import summary\n",
        "\n",
        "# Learning rate scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set device to GPU if available, else use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "rNiOr4uNAhk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed for reproducibility\n",
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjnVLEfjVDNN",
        "outputId": "a36be234-b8e1-4dbd-f6f0-187c6a13c79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7cfc8c7d59d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Base Model"
      ],
      "metadata": {
        "id": "JhvSuJeszeBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model architecture\n",
        "base_n_channels = [32, 32, 64]\n",
        "base_latent_dim = 32\n",
        "\n",
        "# assign dataloaders\n",
        "base_train_dataloader = train_dataloader\n",
        "base_validation_dataloader = validation_dataloader\n",
        "\n",
        "# initialize baseline model\n",
        "base_model = AutoEncoder(\n",
        "    n_channels=base_n_channels,\n",
        "    latent_dim=base_latent_dim\n",
        ").to(device)\n",
        "\n",
        "# define optimizer for baseline model\n",
        "base_optimizer = optim.Adam(base_model.parameters(), lr=1e-3)\n",
        "\n",
        "# define learning rate scheduler (monitors validation loss plateau)\n",
        "base_scheduler = ReduceLROnPlateau(\n",
        "    base_optimizer,\n",
        "    mode='min',\n",
        "    threshold=1e-3,\n",
        "    patience=3,\n",
        "    factor=0.5\n",
        ")\n",
        "\n",
        "# define baseline number of training epochs\n",
        "base_num_epoch = 20\n",
        "\n",
        "# print model summary for baseline model\n",
        "summary(base_model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgasTDzKmsWL",
        "outputId": "0086d4e0-13ef-42b1-e7e7-25f40e7f82b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 14, 14]             544\n",
            "          Identity-2           [-1, 32, 14, 14]               0\n",
            "            Conv2d-3             [-1, 32, 7, 7]          16,416\n",
            "          Identity-4             [-1, 32, 7, 7]               0\n",
            "            Conv2d-5             [-1, 64, 4, 4]          18,496\n",
            "          Identity-6             [-1, 64, 4, 4]               0\n",
            "           Flatten-7                 [-1, 1024]               0\n",
            "            Linear-8                   [-1, 32]          32,800\n",
            "           Encoder-9                   [-1, 32]               0\n",
            "           Linear-10                 [-1, 1024]          33,792\n",
            "        Unflatten-11             [-1, 64, 4, 4]               0\n",
            "  ConvTranspose2d-12             [-1, 32, 7, 7]          18,464\n",
            "         Identity-13             [-1, 32, 7, 7]               0\n",
            "  ConvTranspose2d-14           [-1, 32, 14, 14]          16,416\n",
            "         Identity-15           [-1, 32, 14, 14]               0\n",
            "  ConvTranspose2d-16            [-1, 1, 28, 28]             513\n",
            "          Decoder-17            [-1, 1, 28, 28]               0\n",
            "================================================================\n",
            "Total params: 137,441\n",
            "Trainable params: 137,441\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.29\n",
            "Params size (MB): 0.52\n",
            "Estimated Total Size (MB): 0.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Base Model"
      ],
      "metadata": {
        "id": "L2SJ16uK_udR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train baseline model\n",
        "base_model, base_loss = run_model_training(\n",
        "    model=base_model,\n",
        "    train_dataloader=base_train_dataloader,\n",
        "    validation_dataloader=base_validation_dataloader,\n",
        "    optimizer=base_optimizer,\n",
        "    scheduler=base_scheduler,\n",
        "    num_epoch=base_num_epoch\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMnYUmkC79fY",
        "outputId": "cb0eea6c-2d84-40ce-d515-f25743be5d92",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRAINING IS STARTED:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export and Import"
      ],
      "metadata": {
        "id": "_wNwBkpkuJAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save baseline model weights and loss history locally\n",
        "torch.save(base_model.state_dict(), 'base_model.pth')\n",
        "torch.save(base_loss, 'base_loss.pth')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('base_model.pth')\n",
        "# files.download('base_loss.pth')"
      ],
      "metadata": {
        "id": "SHtkQR5EDHmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: manual upload (Colab only)\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Option 2: load from file path (recommended for reproducibility)\n",
        "base_model = AutoEncoder(n_channels=base_n_channels, latent_dim=base_latent_dim).to(device)\n",
        "base_model.load_state_dict(torch.load('base_model.pth', map_location=torch.device(device)))\n",
        "base_model.eval()\n",
        "\n",
        "base_loss = torch.load('base_loss.pth')"
      ],
      "metadata": {
        "id": "M6aNZfr5asPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_wNwBkpkuJAN"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}